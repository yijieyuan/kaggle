{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34cc8f67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T05:29:23.422549Z",
     "iopub.status.busy": "2024-12-19T05:29:23.422213Z",
     "iopub.status.idle": "2024-12-19T05:29:29.505153Z",
     "shell.execute_reply": "2024-12-19T05:29:29.504006Z"
    },
    "papermill": {
     "duration": 6.091835,
     "end_time": "2024-12-19T05:29:29.507094",
     "exception": false,
     "start_time": "2024-12-19T05:29:23.415259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip -q install /kaggle/input/pytorchtabnet/pytorch_tabnet-4.1.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "680c70e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T05:29:29.519719Z",
     "iopub.status.busy": "2024-12-19T05:29:29.519345Z",
     "iopub.status.idle": "2024-12-19T05:29:39.990225Z",
     "shell.execute_reply": "2024-12-19T05:29:39.989353Z"
    },
    "papermill": {
     "duration": 10.479718,
     "end_time": "2024-12-19T05:29:39.992087",
     "exception": false,
     "start_time": "2024-12-19T05:29:29.512369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import copy\n",
    "import torch\n",
    "import optuna\n",
    "import random\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import torch.nn as nn\n",
    "import lightgbm as lgb\n",
    "import plotly.express as px\n",
    "import torch.optim as optim\n",
    "import polars.selectors as cs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "from sklearn.base import clone\n",
    "from colorama import Fore, Style\n",
    "from scipy.optimize import minimize\n",
    "from IPython.display import clear_output\n",
    "from pytorch_tabnet.callbacks import Callback\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.ensemble import VotingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "SEED = 2024\n",
    "n_splits = 10\n",
    "num_trials = 50\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d6009c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T05:29:40.004262Z",
     "iopub.status.busy": "2024-12-19T05:29:40.003481Z",
     "iopub.status.idle": "2024-12-19T05:29:40.009824Z",
     "shell.execute_reply": "2024-12-19T05:29:40.008800Z"
    },
    "papermill": {
     "duration": 0.014092,
     "end_time": "2024-12-19T05:29:40.011469",
     "exception": false,
     "start_time": "2024-12-19T05:29:39.997377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "    return np.where(oof_non_rounded < thresholds[0], 0,\n",
    "                    np.where(oof_non_rounded < thresholds[1], 1,\n",
    "                             np.where(oof_non_rounded < thresholds[2], 2, 3)))\n",
    "\n",
    "# Define the quadratic weighted kappa evaluation\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "# Function to apply thresholds and convert oof to discrete values\n",
    "def apply_thresholds(oof, thresholds):\n",
    "    return np.digitize(oof, bins=thresholds)\n",
    "\n",
    "# Function to evaluate predictions based on thresholds\n",
    "def evaluate_predictions(thresholds, y_true, oof):\n",
    "    y_pred = apply_thresholds(oof, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, y_pred)  # Negative for minimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1541f7af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T05:29:40.023068Z",
     "iopub.status.busy": "2024-12-19T05:29:40.022663Z",
     "iopub.status.idle": "2024-12-19T05:29:40.048186Z",
     "shell.execute_reply": "2024-12-19T05:29:40.047365Z"
    },
    "papermill": {
     "duration": 0.033283,
     "end_time": "2024-12-19T05:29:40.049895",
     "exception": false,
     "start_time": "2024-12-19T05:29:40.016612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_actigraphy(base_dir):\n",
    "    # Initialize results lists\n",
    "    all_nights_results = []\n",
    "    all_days_results = []\n",
    "    \n",
    "    # Iterate through each ID folder\n",
    "    for id_folder in tqdm(sorted(os.listdir(base_dir))):\n",
    "        id_path = os.path.join(base_dir, id_folder)\n",
    "        parquet_file = os.path.join(id_path, \"part-0.parquet\")\n",
    "    \n",
    "        if not os.path.exists(parquet_file):\n",
    "            continue\n",
    "    \n",
    "        # Read the Parquet file\n",
    "        df = pd.read_parquet(parquet_file)\n",
    "    \n",
    "        # Basic Preprocessing\n",
    "        df['time_of_day'] = (df['time_of_day'] / 1e9).astype(int) # Convert to seconds\n",
    "        start_quarter = df.iloc[0]['quarter'] # Get the start quarter\n",
    "        start_day = int(df['relative_date_PCIAT'].min())\n",
    "        end_day = int(df['relative_date_PCIAT'].max())\n",
    "    \n",
    "        # All-nights analysis\n",
    "        night_results = []\n",
    "        for day in range(start_day, end_day + 1):\n",
    "            # For each day, extract the data between 7 PM and 10 AM the next day, and validate the data(>90% valid data)\n",
    "            sec_1am = 1 * 3600\n",
    "            sec_5am = 5 * 3600\n",
    "            sec_10am = 10 * 3600\n",
    "            sec_7pm = 19 * 3600\n",
    "            sec_start = sec_7pm\n",
    "            sec_end = sec_10am\n",
    "            \n",
    "            condition = (\n",
    "                ((df['relative_date_PCIAT'] == day) & (df['time_of_day'] >= sec_start)) |\n",
    "                ((df['relative_date_PCIAT'] == day + 1) & (df['time_of_day'] < sec_end))\n",
    "            )\n",
    "    \n",
    "            day_data = df[condition].copy()\n",
    "    \n",
    "            total_expected_points = ((24 * 3600 - sec_start) + sec_end) // 5\n",
    "            valid_points = day_data[day_data['non-wear_flag'] != 1].shape[0]\n",
    "            percentage_valid_data = (valid_points / total_expected_points) * 100 if total_expected_points > 0 else 0\n",
    "    \n",
    "            if percentage_valid_data < 90:\n",
    "                continue\n",
    "                \n",
    "            # Calculate the mean ENMO for each 5-minute interval\n",
    "            day_data['time_5min'] = ((day_data['time_of_day'] // 300) * 300)\n",
    "            mean_enmo = day_data.groupby(['relative_date_PCIAT', 'time_5min'])['enmo'].mean().reset_index()\n",
    "    \n",
    "            # Identify the must-be-sleeping data points from mean ENMO\n",
    "            condition_night = (\n",
    "                ((mean_enmo['relative_date_PCIAT'] == day + 1) & (mean_enmo['time_5min'] >= sec_1am)) &\n",
    "                (mean_enmo['time_5min'] <= sec_5am)\n",
    "            )\n",
    "            max_5min_enmo = mean_enmo[condition_night]['enmo'].max() # Get the max mean ENMO during the must-be-sleeping period\n",
    "    \n",
    "            # Identify the sleep and wake candidates\n",
    "            #   - Sleep candidates: ENMO > 1.2 * max_5min_enmo between 7 PM and 1 AM\n",
    "            condition_sleep = (\n",
    "                ((mean_enmo['relative_date_PCIAT'] == day + 1) & ((mean_enmo['time_5min'] < sec_1am))) |\n",
    "                ((mean_enmo['relative_date_PCIAT'] == day) & (mean_enmo['time_5min'] >= sec_7pm))\n",
    "            )\n",
    "            sleep_candidates = mean_enmo[condition_sleep]\n",
    "            sleep_candidates = sleep_candidates[sleep_candidates['enmo'] > 1.2 * max_5min_enmo]\n",
    "            \n",
    "            sleep_time = None\n",
    "            if not sleep_candidates.empty:\n",
    "                for i in range(len(sleep_candidates) - 1):\n",
    "                    if sleep_candidates.iloc[i + 1]['time_5min'] - sleep_candidates.iloc[i]['time_5min'] == 300:\n",
    "                        sleep_time = sleep_candidates.iloc[i + 1]['time_5min']\n",
    "    \n",
    "            if sleep_time is not None and sleep_time < sec_7pm:\n",
    "                sleep_time += 24 * 3600\n",
    "    \n",
    "            #   - Wake candidates: ENMO > 1.2 * max_5min_enmo between 5 AM and 10 AM\n",
    "            condition_wake = ((mean_enmo['relative_date_PCIAT'] == day + 1) & (mean_enmo['time_5min'] > sec_5am))\n",
    "            wake_candidates = mean_enmo[condition_wake]\n",
    "            wake_candidates = wake_candidates[wake_candidates['enmo'] > 1.2 * max_5min_enmo]\n",
    "    \n",
    "            wake_time = None\n",
    "            if not wake_candidates.empty:\n",
    "                for i in range(len(wake_candidates) - 1):\n",
    "                    if wake_candidates.iloc[i + 1]['time_5min'] - wake_candidates.iloc[i]['time_5min'] == 300:\n",
    "                        wake_time = wake_candidates.iloc[i]['time_5min']\n",
    "                        break\n",
    "    \n",
    "            if sleep_time is not None and wake_time is not None:\n",
    "                night_results.append({\n",
    "                    'day': day,\n",
    "                    'percentage_valid_data': percentage_valid_data,\n",
    "                    'sleep_time_sec': sleep_time,\n",
    "                    'wake_time_sec': wake_time,\n",
    "                    'wake_minus_sleep_sec': (wake_time - sleep_time) % (24 * 3600),\n",
    "                    'max_5min_enmo': max_5min_enmo,\n",
    "                })\n",
    "            else:\n",
    "                night_results.append({\n",
    "                    'day': day,\n",
    "                    'percentage_valid_data': percentage_valid_data,\n",
    "                    'sleep_time_sec': np.nan,\n",
    "                    'wake_time_sec': np.nan,\n",
    "                    'wake_minus_sleep_sec': np.nan,\n",
    "                    'max_5min_enmo': max_5min_enmo,\n",
    "                })\n",
    "    \n",
    "        # Now, we have the sleep and wake times for each night, calculate the statistics\n",
    "        if night_results:\n",
    "            valid_nights = pd.DataFrame(night_results).dropna(subset=['sleep_time_sec', 'wake_time_sec'])\n",
    "    \n",
    "            sleep_stats = valid_nights['sleep_time_sec'].agg(['min', 'max', 'mean', 'std']).to_dict()\n",
    "            wake_stats = valid_nights['wake_time_sec'].agg(['min', 'max', 'mean', 'std']).to_dict()\n",
    "            wake_minus_sleep_stats = valid_nights['wake_minus_sleep_sec'].agg(['min', 'max', 'mean', 'std']).to_dict()\n",
    "            enmo_stats = valid_nights['max_5min_enmo'].agg(['min', 'max', 'mean', 'std']).to_dict()\n",
    "    \n",
    "            all_nights_results.append({\n",
    "                'id': id_folder.replace('id=', ''),\n",
    "                'num_valid_nights': len(valid_nights),\n",
    "                'num_total_days': end_day - start_day + 1,\n",
    "                'percentage_valid_nights': len(valid_nights) / (end_day - start_day + 1) * 100,\n",
    "                **{f'sleep_{key}': value for key, value in sleep_stats.items()},\n",
    "                **{f'wake_{key}': value for key, value in wake_stats.items()},\n",
    "                **{f'wake_minus_sleep_{key}': value for key, value in wake_minus_sleep_stats.items()},\n",
    "                **{f'enmo_{key}': value for key, value in enmo_stats.items()}\n",
    "            })\n",
    "        \n",
    "        else:\n",
    "            empty_features = {\n",
    "                'sleep_min': None, 'sleep_max': None, 'sleep_mean': None, 'sleep_std': None,\n",
    "                'wake_min': None, 'wake_max': None, 'wake_mean': None, 'wake_std': None,\n",
    "                'wake_minus_sleep_min': None, 'wake_minus_sleep_max': None, 'wake_minus_sleep_mean': None, 'wake_minus_sleep_std': None,\n",
    "                'enmo_min': None, 'enmo_max': None, 'enmo_mean': None, 'enmo_std': None\n",
    "            }\n",
    "    \n",
    "            # Append the result with features set to None\n",
    "            all_nights_results.append({\n",
    "                'id': id_folder.replace('id=', ''),\n",
    "                'num_valid_nights': 0,\n",
    "                'num_total_days': end_day - start_day + 1,\n",
    "                'percentage_valid_nights': 0,\n",
    "                **empty_features\n",
    "            })\n",
    "    \n",
    "        # All-day analysis\n",
    "        day_results = []\n",
    "    \n",
    "        for day in range(start_day, end_day + 1):\n",
    "            day_data = df[df['relative_date_PCIAT'] == day]\n",
    "            total_valid_points = day_data[day_data['non-wear_flag'] != 1].shape[0] \n",
    "            total_expected_points = 86400 // 5\n",
    "            percentage_valid_data = (total_valid_points / total_expected_points) * 100\n",
    "    \n",
    "            if percentage_valid_data < 90:\n",
    "                continue\n",
    "    \n",
    "            day_mean_enmo = day_data['enmo'].mean()\n",
    "            day_max_enmo = day_data['enmo'].max()\n",
    "            day_std_enmo = day_data['enmo'].std()\n",
    "            day_mean_light = day_data['light'].mean()\n",
    "            day_max_light = day_data['light'].max()\n",
    "            day_std_light = day_data['light'].std()\n",
    "    \n",
    "            day_results.append({\n",
    "                'day': day,\n",
    "                'mean_enmo': day_mean_enmo,\n",
    "                'max_enmo': day_max_enmo,\n",
    "                'std_enmo': day_std_enmo,\n",
    "                'mean_light': day_mean_light,\n",
    "                'max_light': day_max_light,\n",
    "                'std_light': day_std_light\n",
    "            })\n",
    "    \n",
    "        if day_results:\n",
    "            valid_days = pd.DataFrame(day_results)\n",
    "            all_days_results.append({\n",
    "                'id': id_folder.replace('id=', ''),\n",
    "                'num_valid_days': len(valid_days),\n",
    "                'quarter': start_quarter,\n",
    "                'percentage_valid_days': len(valid_days) / (end_day - start_day + 1) * 100,\n",
    "                **{f'{stat}_{metric}': valid_days[stat].agg(metric) for stat in ['mean_enmo', 'max_enmo', 'std_enmo', 'mean_light', 'max_light', 'std_light'] for metric in ['mean', 'min', 'max', 'std']}\n",
    "                })\n",
    "    \n",
    "        else:\n",
    "            empty_features = {f'{base}_{metric}': np.nan for base  in ['mean_enmo', 'max_enmo', 'std_enmo', 'mean_light', 'max_light', 'std_light'] for metric in ['mean', 'min', 'max', 'std']}\n",
    "            all_days_results.append({\n",
    "                'id': id_folder.replace('id=', ''),\n",
    "                'num_valid_days': 0,\n",
    "                'quarter': start_quarter,\n",
    "                'percentage_valid_days': 0,\n",
    "                **empty_features\n",
    "            })\n",
    "    \n",
    "    # Combine results into a single DataFrame\n",
    "    all_night_df = pd.DataFrame(all_nights_results)\n",
    "    all_day_df = pd.DataFrame(all_days_results)\n",
    "    \n",
    "    # for all col in all_day_df with 'std' in the last 4 characters, fill NaN with 0 if num_valid_days is not 0\n",
    "    for col in all_day_df.columns:\n",
    "        if 'std' in col[-4:]:\n",
    "            all_day_df[col] = all_day_df[col][all_day_df['num_valid_days'] != 0].fillna(0)\n",
    "    \n",
    "    # for all col in all_night_df with 'std' in the last 4 characters, fill NaN with 0 if num_valid_nights is not 0\n",
    "    for col in all_night_df.columns:\n",
    "        if 'std' in col[-4:]:\n",
    "            all_night_df[col] = all_night_df[col][all_night_df['num_valid_nights'] != 0].fillna(0)\n",
    "    \n",
    "    df_act = pd.merge(all_night_df, all_day_df, on='id', how='outer')\n",
    "    return df_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99320add",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T05:29:40.061309Z",
     "iopub.status.busy": "2024-12-19T05:29:40.060984Z",
     "iopub.status.idle": "2024-12-19T05:34:54.646860Z",
     "shell.execute_reply": "2024-12-19T05:34:54.645788Z"
    },
    "papermill": {
     "duration": 314.593726,
     "end_time": "2024-12-19T05:34:54.648833",
     "exception": false,
     "start_time": "2024-12-19T05:29:40.055107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [05:11<00:00,  3.20it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.19it/s]\n"
     ]
    }
   ],
   "source": [
    "def feature_engineering(df):\n",
    "    # season_cols = [col for col in df.columns if 'Season' in col]\n",
    "    # df = df.drop(season_cols, axis=1) \n",
    "    df['BMI_Age'] = df['Physical-BMI'] * df['Basic_Demos-Age']\n",
    "    df['Internet_Hours_Age'] = df['PreInt_EduHx-computerinternet_hoursday'] * df['Basic_Demos-Age']\n",
    "    df['BMI_Internet_Hours'] = df['Physical-BMI'] * df['PreInt_EduHx-computerinternet_hoursday']\n",
    "    df['BFP_BMI'] = df['BIA-BIA_Fat'] / df['BIA-BIA_BMI']\n",
    "    df['FFMI_BFP'] = df['BIA-BIA_FFMI'] / df['BIA-BIA_Fat']\n",
    "    df['FMI_BFP'] = df['BIA-BIA_FMI'] / df['BIA-BIA_Fat']\n",
    "    df['LST_TBW'] = df['BIA-BIA_LST'] / df['BIA-BIA_TBW']\n",
    "    df['BFP_BMR'] = df['BIA-BIA_Fat'] * df['BIA-BIA_BMR']\n",
    "    df['BFP_DEE'] = df['BIA-BIA_Fat'] * df['BIA-BIA_DEE']\n",
    "    df['BMR_Weight'] = df['BIA-BIA_BMR'] / df['Physical-Weight']\n",
    "    df['DEE_Weight'] = df['BIA-BIA_DEE'] / df['Physical-Weight']\n",
    "    df['SMM_Height'] = df['BIA-BIA_SMM'] / df['Physical-Height']\n",
    "    df['Muscle_to_Fat'] = df['BIA-BIA_SMM'] / df['BIA-BIA_FMI']\n",
    "    df['Hydration_Status'] = df['BIA-BIA_TBW'] / df['Physical-Weight']\n",
    "    df['ICW_TBW'] = df['BIA-BIA_ICW'] / df['BIA-BIA_TBW']\n",
    "    df['BMI_PHR'] = df['Physical-BMI'] * df['Physical-HeartRate']\n",
    "    return df\n",
    "\n",
    "base = '/kaggle/input/child-mind-institute-problematic-internet-use/'\n",
    "intermediate_base = '/kaggle/working'\n",
    "\n",
    "# base = 'D:\\Kaggle\\CMI\\child-mind-institute-problematic-internet-use'\n",
    "# intermediate_base = './'\n",
    "\n",
    "dirpath_train_ts = os.path.join(base, 'series_train.parquet')\n",
    "dirpath_test_ts = os.path.join(base, 'series_test.parquet')\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(base, 'train.csv'))\n",
    "df_test = pd.read_csv(os.path.join(base, 'test.csv'))\n",
    "sample = pd.read_csv(os.path.join(base, 'sample_submission.csv'))\n",
    "df_train = df_train.dropna(subset=['sii']).reset_index(drop=True)\n",
    "\n",
    "df_train.loc[df_train['BIA-BIA_Fat'] < 0, 'BIA-BIA_Fat'] = np.nan\n",
    "df_train.loc[df_train['BIA-BIA_FMI'] < 0, 'BIA-BIA_FMI'] = np.nan\n",
    "\n",
    "load_actigraphy = True\n",
    "save_actigraphy = True\n",
    "\n",
    "# Compute time-series features\n",
    "if os.path.exists(os.path.join(intermediate_base, 'df_train_actigraphy.csv')) and os.path.exists(os.path.join(intermediate_base, 'df_test_actigraphy.csv')) and load_actigraphy:\n",
    "    df_train_actigraphy = pd.read_csv(os.path.join(intermediate_base, 'df_train_actigraphy.csv'))\n",
    "    df_test_actigraphy = pd.read_csv(os.path.join(intermediate_base, 'df_test_actigraphy.csv'))\n",
    "    \n",
    "else:\n",
    "    # results_train = process_actigraphy(id_paths_train)\n",
    "    # results_test = process_actigraphy(id_paths_test)\n",
    "    # df_train_actigraphy = pd.DataFrame(results_train, columns=['id'] + ['actigraphy_' + str(i) for i in range(len(results_train[0])-1)])\n",
    "    # df_test_actigraphy = pd.DataFrame(results_test, columns=['id'] + ['actigraphy_' + str(i) for i in range(len(results_test[0])-1)])\n",
    "\n",
    "    df_train_actigraphy = process_actigraphy(dirpath_train_ts)\n",
    "    df_test_actigraphy = process_actigraphy(dirpath_test_ts)\n",
    "\n",
    "    if save_actigraphy:\n",
    "        df_train_actigraphy.to_csv(os.path.join(intermediate_base, 'df_train_actigraphy.csv'), index=False)\n",
    "        df_test_actigraphy.to_csv(os.path.join(intermediate_base, 'df_test_actigraphy.csv'), index=False)\n",
    "    \n",
    "\n",
    "df_train_actigraphy_encoded = df_train_actigraphy\n",
    "df_test_actigraphy_encoded = df_test_actigraphy\n",
    "\n",
    "# df_train_actigraphy_encoded = encode(df_train_actigraphy, encoding_dim=60, epochs=100, batch_size=32)\n",
    "# df_test_actigraphy_encoded = encode(df_test_actigraphy, encoding_dim=60, epochs=100, batch_size=32)\n",
    "# df_train_actigraphy_encoded['id'] = df_train_actigraphy['id']\n",
    "# df_test_actigraphy_encoded['id'] = df_test_actigraphy['id']\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "numeric_cols_train = [col for col in df_test.select_dtypes(include=['float64', 'int64']).columns \n",
    "                      if 'sii' not in col.lower() and 'pciat' not in col.lower()]\n",
    "numeric_cols_test = [col for col in df_test.select_dtypes(include=['float64', 'int64']).columns \n",
    "                      if 'sii' not in col.lower() and 'pciat' not in col.lower()]\n",
    "df_all = pd.concat([df_train[numeric_cols_train], df_test[numeric_cols_test]], axis=0)\n",
    "imputer.fit(df_all)\n",
    "\n",
    "df_train_imputed = pd.DataFrame(imputer.transform(df_train[numeric_cols_train]), columns=numeric_cols_train)\n",
    "df_test_imputed = pd.DataFrame(imputer.transform(df_test[numeric_cols_test]), columns=numeric_cols_test)\n",
    "\n",
    "for col in df_train.columns:\n",
    "    if col not in numeric_cols_train:\n",
    "        df_train_imputed[col] = df_train[col]\n",
    "\n",
    "for col in df_test.columns:\n",
    "    if col not in numeric_cols_test:\n",
    "        df_test_imputed[col] = df_test[col]\n",
    "\n",
    "df_train = df_train_imputed\n",
    "df_train = feature_engineering(df_train)\n",
    "\n",
    "df_test = df_test_imputed\n",
    "df_test = feature_engineering(df_test)\n",
    "\n",
    "df_train = pd.merge(df_train, df_train_actigraphy_encoded, how='left', on='id')\n",
    "df_test = pd.merge(df_test, df_test_actigraphy_encoded, how='left', on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f89e5e",
   "metadata": {
    "papermill": {
     "duration": 0.05313,
     "end_time": "2024-12-19T05:34:54.757866",
     "exception": false,
     "start_time": "2024-12-19T05:34:54.704736",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission 1 - Tabular + Customized Actigraphy | KNN Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15eb7d64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T05:34:54.866822Z",
     "iopub.status.busy": "2024-12-19T05:34:54.866422Z",
     "iopub.status.idle": "2024-12-19T05:34:54.877291Z",
     "shell.execute_reply": "2024-12-19T05:34:54.876249Z"
    },
    "papermill": {
     "duration": 0.068046,
     "end_time": "2024-12-19T05:34:54.879236",
     "exception": false,
     "start_time": "2024-12-19T05:34:54.811190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "featuresCols = ['Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "                'CGAS-CGAS_Score', 'Physical-BMI',\n",
    "                'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "                'Fitness_Endurance-Max_Stage',\n",
    "                'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "                'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "                'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "                'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "                'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone',\n",
    "                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "                'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "                'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "                'BIA-BIA_TBW', 'PAQ_A-PAQ_A_Total',\n",
    "                'PAQ_C-PAQ_C_Total', 'SDS-SDS_Total_Raw',\n",
    "                'SDS-SDS_Total_T',\n",
    "                'PreInt_EduHx-computerinternet_hoursday']\n",
    "\n",
    "actigraphy_features = [col for col in df_test_actigraphy_encoded.columns if 'id' not in col]\n",
    "\n",
    "target = 'sii'\n",
    "\n",
    "additional_features = []\n",
    "df_train = df_train[featuresCols + actigraphy_features + [target]]\n",
    "df_test = df_test[featuresCols + actigraphy_features]\n",
    "\n",
    "if np.any(np.isinf(df_train)):\n",
    "    df_train = df_train.replace([np.inf, -np.inf], np.nan)\n",
    "if np.any(np.isinf(df_test)):\n",
    "    df_test = df_test.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4b6b636",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T05:34:54.990055Z",
     "iopub.status.busy": "2024-12-19T05:34:54.989636Z",
     "iopub.status.idle": "2024-12-19T06:07:51.940043Z",
     "shell.execute_reply": "2024-12-19T06:07:51.938896Z"
    },
    "papermill": {
     "duration": 1977.008107,
     "end_time": "2024-12-19T06:07:51.941554",
     "exception": false,
     "start_time": "2024-12-19T05:34:54.933447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds: 100%|██████████| 10/10 [00:04<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train QWK --> 0.4962\n",
      "Mean Valid QWK --> 0.3916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10201it [00:30, 330.07it/s]\n",
      "1001it [00:03, 328.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reproduced Score:  -0.4928209308509479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008ff9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fd460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00105258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00115b9f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016bb22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001f3379</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0038ba98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0068a485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0069fbed</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0083e397</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0087dd65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00abe655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00ae59c9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00af6387</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00bd4359</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00c0cd71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00d56d4b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00d9913d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00e6167c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00ebc35d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  sii\n",
       "0   00008ff9    0\n",
       "1   000fd460    0\n",
       "2   00105258    0\n",
       "3   00115b9f    0\n",
       "4   0016bb22    2\n",
       "5   001f3379    0\n",
       "6   0038ba98    1\n",
       "7   0068a485    0\n",
       "8   0069fbed    2\n",
       "9   0083e397    2\n",
       "10  0087dd65    1\n",
       "11  00abe655    1\n",
       "12  00ae59c9    1\n",
       "13  00af6387    2\n",
       "14  00bd4359    2\n",
       "15  00c0cd71    1\n",
       "16  00d56d4b    0\n",
       "17  00d9913d    0\n",
       "18  00e6167c    0\n",
       "19  00ebc35d    1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optuna objective function\n",
    "# open a .txt\n",
    "\n",
    "def train(params, trial_number):\n",
    "    X = df_train.drop(['sii'], axis=1)\n",
    "    y = df_train['sii']\n",
    "\n",
    "    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "        \n",
    "    list_train_kappas = []\n",
    "    list_valid_kappas = []\n",
    "    oof_non_rounded = np.zeros(len(y), dtype=float) \n",
    "    oof_rounded = np.zeros(len(y), dtype=int) \n",
    "    y_test = np.zeros((len(df_test), n_splits))\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = LGBMRegressor(**params)\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            callbacks=[\n",
    "            lgb.early_stopping(10000),           # Early stopping after 50 rounds\n",
    "            lgb.log_evaluation(period=10000)],    # Log evaluation metrics every 10 rounds\n",
    "        )\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        oof_non_rounded[test_idx] = y_val_pred\n",
    "        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "        oof_rounded[test_idx] = y_val_pred_rounded\n",
    "\n",
    "        train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n",
    "        valid_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
    "        list_train_kappas.append(train_kappa)\n",
    "        list_valid_kappas.append(valid_kappa)\n",
    "    \n",
    "        y_test[:, fold] = model.predict(df_test)\n",
    "        clear_output(wait=True)\n",
    "            \n",
    "    print(f\"Mean Train QWK --> {np.mean(list_train_kappas):.4f}\")\n",
    "    print(f\"Mean Valid QWK --> {np.mean(list_valid_kappas):.4f}\")\n",
    "\n",
    "    # Grid sweep setup\n",
    "    threshold_ranges = [\n",
    "        np.linspace(0.25, 0.75, 101, endpoint=True),   # First threshold range\n",
    "        np.linspace(0.75, 1.25, 101, endpoint=True), # Second threshold range\n",
    "        [3],\n",
    "    ]\n",
    "\n",
    "    # Prepare the grid search\n",
    "    best_score = float('-inf')\n",
    "    best_thresholds = None\n",
    "\n",
    "    for thresholds in tqdm(product(*threshold_ranges)):\n",
    "        thresholds = sorted(thresholds)  # Ensure thresholds are in order\n",
    "        score = -evaluate_predictions(thresholds, y, oof_non_rounded)  # Flip back to positive\n",
    "        if score > best_score:\n",
    "            # print(\"Score: \", score, \"thresholds: \", thresholds)\n",
    "            best_score = score\n",
    "            best_thresholds = thresholds\n",
    "\n",
    "    threshold_ranges = [\n",
    "        [best_thresholds[0]],\n",
    "        [best_thresholds[1]],\n",
    "        np.linspace(best_thresholds[1], 3.5, 1001, endpoint=True)    # Third threshold range\n",
    "    ]\n",
    "\n",
    "    for thresholds in tqdm(product(*threshold_ranges)):\n",
    "        thresholds = sorted(thresholds)  # Ensure thresholds are in order\n",
    "        score = -evaluate_predictions(thresholds, y, oof_non_rounded)  # Flip back to positive\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_thresholds = thresholds\n",
    "    \n",
    "    oof_tuned = threshold_Rounder(oof_non_rounded, best_thresholds)\n",
    "    oof_kappa = quadratic_weighted_kappa(y, oof_tuned)\n",
    "\n",
    "    y_test = y_test.mean(axis=1)\n",
    "    y_test = threshold_Rounder(y_test, best_thresholds)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'id': sample['id'],\n",
    "            'sii': y_test\n",
    "        })\n",
    "\n",
    "    # write to the .txt\n",
    "    f.write(f\"Trial: {trial_number}\\n\")\n",
    "    f.write(f\"Params: {params}\\n\")\n",
    "    f.write(f\"Score: {best_score}\\n\")\n",
    "    f.write(f\"Thresholds: {best_thresholds}\\n\")\n",
    "    f.write(f\"Train Kappa: {np.mean(list_train_kappas):.4f}\\n\")\n",
    "    f.write(f\"Validation Kappa: {np.mean(list_valid_kappas):.4f}\\n\")\n",
    "    f.write(f\"Optimized OOF QWK: {oof_kappa:.3f}\\n\")\n",
    "    f.write(f\"Best Score: {best_score}\\n\\n\")\n",
    "    f.write(\"-\" * 100 + \"\\n\")\n",
    "    f.flush()\n",
    "\n",
    "    return -oof_kappa, submission, oof_tuned\n",
    "\n",
    "with open('LGBM_Optimization.txt', 'w') as f:\n",
    "    f.write('Submission 1 - Optimization started\\n')\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, step=0.01),  # Replaced suggest_loguniform\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 300, step=50),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 7, step=1),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 16, 512, step=2),\n",
    "            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 16, 128),\n",
    "            'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0, step=0.01),  # Replaced suggest_uniform\n",
    "            'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0, step=0.01),  # Replaced suggest_uniform\n",
    "            'bagging_freq': trial.suggest_int('bagging_freq', 1, 10, step=1),\n",
    "            \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 10, step=1),\n",
    "            \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 10, step=1),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0, step=0.1),  # Replaced suggest_uniform\n",
    "            'colsample_bynode': trial.suggest_float('colsample_bynode', 0.5, 1.0, step=0.1),  # Replaced suggest_uniform\n",
    "            'verbose': -1, # Disable LightGBM verbose logging\n",
    "            'random_state': SEED\n",
    "        }\n",
    "\n",
    "        score, submission, oof_tuned = train(params, trial.number)\n",
    "        return score\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\", study_name=\"LGBM Optimization\")\n",
    "    study.optimize(objective, n_trials=num_trials)\n",
    "    best_params = study.best_params\n",
    "    best_score = study.best_value\n",
    "    print(f\"Best Score: {best_score}\")\n",
    "    print(f\"Best Params: {best_params}\")\n",
    "\n",
    "    best_params['random_state'] = SEED\n",
    "    score, submission1, oof_tuned1 = train(best_params, study.best_trial.number)\n",
    "    print(\"Reproduced Score: \", score)\n",
    "\n",
    "submission1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d0551a",
   "metadata": {
    "papermill": {
     "duration": 0.074185,
     "end_time": "2024-12-19T06:07:52.088828",
     "exception": false,
     "start_time": "2024-12-19T06:07:52.014643",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission 2 - Tabular Only | KNN Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "776aa744",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T06:07:52.238799Z",
     "iopub.status.busy": "2024-12-19T06:07:52.238365Z",
     "iopub.status.idle": "2024-12-19T06:07:52.249055Z",
     "shell.execute_reply": "2024-12-19T06:07:52.247947Z"
    },
    "papermill": {
     "duration": 0.086398,
     "end_time": "2024-12-19T06:07:52.250837",
     "exception": false,
     "start_time": "2024-12-19T06:07:52.164439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "featuresCols = ['Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "                'CGAS-CGAS_Score', 'Physical-BMI',\n",
    "                'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "                'Fitness_Endurance-Max_Stage',\n",
    "                'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "                'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "                'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "                'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "                'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone',\n",
    "                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "                'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "                'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "                'BIA-BIA_TBW', 'PAQ_A-PAQ_A_Total',\n",
    "                'PAQ_C-PAQ_C_Total', 'SDS-SDS_Total_Raw',\n",
    "                'SDS-SDS_Total_T',\n",
    "                'PreInt_EduHx-computerinternet_hoursday']\n",
    "\n",
    "target = 'sii'\n",
    "df_train = df_train[featuresCols  + [target]]\n",
    "df_test = df_test[featuresCols]\n",
    "\n",
    "if np.any(np.isinf(df_train)):\n",
    "    df_train = df_train.replace([np.inf, -np.inf], np.nan)\n",
    "if np.any(np.isinf(df_test)):\n",
    "    df_test = df_test.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01bd51bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T06:07:52.403369Z",
     "iopub.status.busy": "2024-12-19T06:07:52.403007Z",
     "iopub.status.idle": "2024-12-19T06:38:47.282522Z",
     "shell.execute_reply": "2024-12-19T06:38:47.281577Z"
    },
    "papermill": {
     "duration": 1854.95781,
     "end_time": "2024-12-19T06:38:47.283911",
     "exception": false,
     "start_time": "2024-12-19T06:07:52.326101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds: 100%|██████████| 10/10 [00:02<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train QWK --> 0.4546\n",
      "Mean Valid QWK --> 0.3853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10201it [00:28, 355.21it/s]\n",
      "1001it [00:02, 364.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reproduced Score:  -0.4954341763489599\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008ff9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fd460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00105258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00115b9f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016bb22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001f3379</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0038ba98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0068a485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0069fbed</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0083e397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0087dd65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00abe655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00ae59c9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00af6387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00bd4359</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00c0cd71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00d56d4b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00d9913d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00e6167c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00ebc35d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  sii\n",
       "0   00008ff9    1\n",
       "1   000fd460    0\n",
       "2   00105258    1\n",
       "3   00115b9f    0\n",
       "4   0016bb22    2\n",
       "5   001f3379    1\n",
       "6   0038ba98    1\n",
       "7   0068a485    0\n",
       "8   0069fbed    2\n",
       "9   0083e397    1\n",
       "10  0087dd65    1\n",
       "11  00abe655    1\n",
       "12  00ae59c9    1\n",
       "13  00af6387    1\n",
       "14  00bd4359    2\n",
       "15  00c0cd71    1\n",
       "16  00d56d4b    0\n",
       "17  00d9913d    0\n",
       "18  00e6167c    0\n",
       "19  00ebc35d    1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optuna objective function\n",
    "# open a .txt\n",
    "\n",
    "def train(params, trial_number):\n",
    "    X = df_train.drop(['sii'], axis=1)\n",
    "    y = df_train['sii']\n",
    "\n",
    "    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "        \n",
    "    list_train_kappas = []\n",
    "    list_valid_kappas = []\n",
    "    oof_non_rounded = np.zeros(len(y), dtype=float) \n",
    "    oof_rounded = np.zeros(len(y), dtype=int) \n",
    "    y_test = np.zeros((len(df_test), n_splits))\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = LGBMRegressor(**params)\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            callbacks=[\n",
    "            lgb.early_stopping(10000),           # Early stopping after 50 rounds\n",
    "            lgb.log_evaluation(period=10000)],    # Log evaluation metrics every 10 rounds\n",
    "        )\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        oof_non_rounded[test_idx] = y_val_pred\n",
    "        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "        oof_rounded[test_idx] = y_val_pred_rounded\n",
    "\n",
    "        train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n",
    "        valid_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
    "        list_train_kappas.append(train_kappa)\n",
    "        list_valid_kappas.append(valid_kappa)\n",
    "    \n",
    "        y_test[:, fold] = model.predict(df_test)\n",
    "        clear_output(wait=True)\n",
    "            \n",
    "    print(f\"Mean Train QWK --> {np.mean(list_train_kappas):.4f}\")\n",
    "    print(f\"Mean Valid QWK --> {np.mean(list_valid_kappas):.4f}\")\n",
    "\n",
    "    # Grid sweep setup\n",
    "    threshold_ranges = [\n",
    "        np.linspace(0.25, 0.75, 101, endpoint=True),   # First threshold range\n",
    "        np.linspace(0.75, 1.25, 101, endpoint=True), # Second threshold range\n",
    "        [3],\n",
    "    ]\n",
    "\n",
    "    # Prepare the grid search\n",
    "    best_score = float('-inf')\n",
    "    best_thresholds = None\n",
    "\n",
    "    for thresholds in tqdm(product(*threshold_ranges)):\n",
    "        thresholds = sorted(thresholds)  # Ensure thresholds are in order\n",
    "        score = -evaluate_predictions(thresholds, y, oof_non_rounded)  # Flip back to positive\n",
    "        if score > best_score:\n",
    "            # print(\"Score: \", score, \"thresholds: \", thresholds)\n",
    "            best_score = score\n",
    "            best_thresholds = thresholds\n",
    "\n",
    "    threshold_ranges = [\n",
    "        [best_thresholds[0]],\n",
    "        [best_thresholds[1]],\n",
    "        np.linspace(best_thresholds[1], 3.5, 1001, endpoint=True)    # Third threshold range\n",
    "    ]\n",
    "\n",
    "    for thresholds in tqdm(product(*threshold_ranges)):\n",
    "        thresholds = sorted(thresholds)  # Ensure thresholds are in order\n",
    "        score = -evaluate_predictions(thresholds, y, oof_non_rounded)  # Flip back to positive\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_thresholds = thresholds\n",
    "    \n",
    "    oof_tuned = threshold_Rounder(oof_non_rounded, best_thresholds)\n",
    "    oof_kappa = quadratic_weighted_kappa(y, oof_tuned)\n",
    "\n",
    "    y_test = y_test.mean(axis=1)\n",
    "    y_test = threshold_Rounder(y_test, best_thresholds)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'id': sample['id'],\n",
    "            'sii': y_test\n",
    "        })\n",
    "\n",
    "    # write to the .txt\n",
    "    f.write(f\"Trial: {trial_number}\\n\")\n",
    "    f.write(f\"Params: {params}\\n\")\n",
    "    f.write(f\"Score: {best_score}\\n\")\n",
    "    f.write(f\"Thresholds: {best_thresholds}\\n\")\n",
    "    f.write(f\"Train Kappa: {np.mean(list_train_kappas):.4f}\\n\")\n",
    "    f.write(f\"Validation Kappa: {np.mean(list_valid_kappas):.4f}\\n\")\n",
    "    f.write(f\"Optimized OOF QWK: {oof_kappa:.3f}\\n\")\n",
    "    f.write(f\"Best Score: {best_score}\\n\\n\")\n",
    "    f.write(\"-\" * 100 + \"\\n\")\n",
    "    f.flush()\n",
    "\n",
    "    return -oof_kappa, submission, oof_tuned\n",
    "\n",
    "\n",
    "with open('LGBM_Optimization.txt', 'a') as f:\n",
    "    f.write('Submission 2 - Optimization started\\n')\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, step=0.01),  # Replaced suggest_loguniform\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 300, step=50),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 7, step=1),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 16, 512, step=2),\n",
    "            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 16, 128),\n",
    "            'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0, step=0.01),  # Replaced suggest_uniform\n",
    "            'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0, step=0.01),  # Replaced suggest_uniform\n",
    "            'bagging_freq': trial.suggest_int('bagging_freq', 1, 10, step=1),\n",
    "            \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 10, step=1),\n",
    "            \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 10, step=1),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0, step=0.1),  # Replaced suggest_uniform\n",
    "            'colsample_bynode': trial.suggest_float('colsample_bynode', 0.5, 1.0, step=0.1),  # Replaced suggest_uniform\n",
    "            'verbose': -1, # Disable LightGBM verbose logging\n",
    "            'random_state': SEED\n",
    "        }\n",
    "\n",
    "        score, submission, oof_tuned = train(params, trial.number)\n",
    "        return score\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\", study_name=\"LGBM Optimization\")\n",
    "    study.optimize(objective, n_trials=num_trials)\n",
    "    best_params = study.best_params\n",
    "    best_score = study.best_value\n",
    "    print(f\"Best Score: {best_score}\")\n",
    "    print(f\"Best Params: {best_params}\")\n",
    "    \n",
    "    best_params['random_state'] = SEED\n",
    "    score, submission2, oof_tuned2 = train(best_params, study.best_trial.number)\n",
    "    print(\"Reproduced Score: \", score)\n",
    "\n",
    "submission2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73f7de5",
   "metadata": {
    "papermill": {
     "duration": 0.079541,
     "end_time": "2024-12-19T06:38:47.443385",
     "exception": false,
     "start_time": "2024-12-19T06:38:47.363844",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission 3 - Tabular + Customized Actigraphy | Median Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd0a28e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T06:38:47.608297Z",
     "iopub.status.busy": "2024-12-19T06:38:47.607996Z",
     "iopub.status.idle": "2024-12-19T06:38:47.718223Z",
     "shell.execute_reply": "2024-12-19T06:38:47.717500Z"
    },
    "papermill": {
     "duration": 0.195034,
     "end_time": "2024-12-19T06:38:47.719734",
     "exception": false,
     "start_time": "2024-12-19T06:38:47.524700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(base, 'train.csv'))\n",
    "df_test = pd.read_csv(os.path.join(base, 'test.csv'))\n",
    "df_train = pd.merge(df_train, df_train_actigraphy, how='left', on='id')\n",
    "df_test = pd.merge(df_test, df_test_actigraphy, how='left', on='id')\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "numeric_cols_train = [col for col in df_train.select_dtypes(include=['float64', 'int64']).columns if 'sii' not in col.lower() and 'pciat' not in col.lower()]\n",
    "numeric_cols_test = [col for col in df_test.select_dtypes(include=['float64', 'int64']).columns if 'sii' not in col.lower() and 'pciat' not in col.lower()]\n",
    "imputer.fit(df_train[numeric_cols_train])\n",
    "\n",
    "df_train_imputed = pd.DataFrame(imputer.transform(df_train[numeric_cols_train]), columns=numeric_cols_train)\n",
    "df_test_imputed = pd.DataFrame(imputer.transform(df_test[numeric_cols_test]), columns=numeric_cols_test)\n",
    "\n",
    "for col in df_train.columns:\n",
    "    if col not in numeric_cols_train:\n",
    "        df_train_imputed[col] = df_train[col]\n",
    "\n",
    "for col in df_test.columns:\n",
    "    if col not in numeric_cols_test:\n",
    "        df_test_imputed[col] = df_test[col]\n",
    "\n",
    "df_train = df_train_imputed\n",
    "df_test = df_test_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9df4ee19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T06:38:47.881586Z",
     "iopub.status.busy": "2024-12-19T06:38:47.881278Z",
     "iopub.status.idle": "2024-12-19T06:38:47.944042Z",
     "shell.execute_reply": "2024-12-19T06:38:47.943220Z"
    },
    "papermill": {
     "duration": 0.145153,
     "end_time": "2024-12-19T06:38:47.945540",
     "exception": false,
     "start_time": "2024-12-19T06:38:47.800387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "season_cols = ['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', 'Fitness_Endurance-Season', 'FGC-Season', 'BIA-Season', 'PAQ_A-Season', 'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season']\n",
    "\n",
    "feature_cols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "                'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI',\n",
    "                'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "                'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n",
    "                'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "                'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "                'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "                'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "                'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n",
    "                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "                'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "                'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "                'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season',\n",
    "                'PAQ_C-PAQ_C_Total', 'SDS-Season', 'SDS-SDS_Total_Raw',\n",
    "                'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n",
    "                'PreInt_EduHx-computerinternet_hoursday']\n",
    "\n",
    "actigraphy_features = [col for col in df_train_actigraphy.columns if 'id' not in col]\n",
    "target = 'sii'\n",
    "\n",
    "df_train = df_train[feature_cols + actigraphy_features + [target]]\n",
    "df_test = df_test[feature_cols + actigraphy_features]\n",
    "df_train = df_train.dropna(subset='sii')\n",
    "\n",
    "for col in season_cols: \n",
    "    df_train[col] = df_train[col].fillna('Missing')\n",
    "    df_test[col] = df_test[col].fillna('Missing')\n",
    "    df_train[col] = df_train[col].astype('category')\n",
    "    df_test[col] = df_test[col].astype('category')\n",
    "\n",
    "    unique_values_train = df_train[col].unique()\n",
    "    unique_values_test = df_test[col].unique()\n",
    "    unique_values = np.unique(np.concatenate([unique_values_train, unique_values_test]))\n",
    "    catToNumberTrain = {value: idx for idx, value in enumerate(unique_values_train)}\n",
    "    catToNumberTest = {value: idx for idx, value in enumerate(unique_values_test)}\n",
    "    catToNumber = {value: idx for idx, value in enumerate(unique_values)}\n",
    "    \n",
    "    df_train[col] = df_train[col].replace(catToNumber) \n",
    "    df_test[col] = df_test[col].replace(catToNumber)\n",
    "\n",
    "# check how many cols has missing values\n",
    "missing_cols = df_train.columns[df_train.isnull().any()]\n",
    "missing_cols\n",
    "\n",
    "# if np.any(np.isinf(df_train)):\n",
    "#     df_train = df_train.replace([np.inf, -np.inf], np.nan)\n",
    "# if np.any(np.isinf(df_test)):\n",
    "#     df_test = df_test.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7a5e4c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T06:38:48.111874Z",
     "iopub.status.busy": "2024-12-19T06:38:48.111495Z",
     "iopub.status.idle": "2024-12-19T07:09:52.971950Z",
     "shell.execute_reply": "2024-12-19T07:09:52.971084Z"
    },
    "papermill": {
     "duration": 1864.945397,
     "end_time": "2024-12-19T07:09:52.973354",
     "exception": false,
     "start_time": "2024-12-19T06:38:48.027957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds: 100%|██████████| 10/10 [00:02<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train QWK --> 0.4456\n",
      "Mean Valid QWK --> 0.3747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10201it [00:30, 339.46it/s]\n",
      "1001it [00:02, 334.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reproduced Score:  -0.49599542536030583\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008ff9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fd460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00105258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00115b9f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016bb22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001f3379</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0038ba98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0068a485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0069fbed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0083e397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0087dd65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00abe655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00ae59c9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00af6387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00bd4359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00c0cd71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00d56d4b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00d9913d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00e6167c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00ebc35d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  sii\n",
       "0   00008ff9    0\n",
       "1   000fd460    0\n",
       "2   00105258    0\n",
       "3   00115b9f    0\n",
       "4   0016bb22    1\n",
       "5   001f3379    0\n",
       "6   0038ba98    1\n",
       "7   0068a485    0\n",
       "8   0069fbed    1\n",
       "9   0083e397    1\n",
       "10  0087dd65    0\n",
       "11  00abe655    0\n",
       "12  00ae59c9    1\n",
       "13  00af6387    1\n",
       "14  00bd4359    1\n",
       "15  00c0cd71    0\n",
       "16  00d56d4b    0\n",
       "17  00d9913d    0\n",
       "18  00e6167c    0\n",
       "19  00ebc35d    1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optuna objective function\n",
    "# open a .txt\n",
    "\n",
    "def train(params, trial_number):\n",
    "    X = df_train.drop(['sii'], axis=1)\n",
    "    y = df_train['sii']\n",
    "\n",
    "    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "        \n",
    "    list_train_kappas = []\n",
    "    list_valid_kappas = []\n",
    "    oof_non_rounded = np.zeros(len(y), dtype=float) \n",
    "    oof_rounded = np.zeros(len(y), dtype=int) \n",
    "    y_test = np.zeros((len(df_test), n_splits))\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = LGBMRegressor(**params)\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            callbacks=[\n",
    "            lgb.early_stopping(10000),           # Early stopping after 50 rounds\n",
    "            lgb.log_evaluation(period=10000)],    # Log evaluation metrics every 10 rounds\n",
    "        )\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        oof_non_rounded[test_idx] = y_val_pred\n",
    "        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "        oof_rounded[test_idx] = y_val_pred_rounded\n",
    "\n",
    "        train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n",
    "        valid_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
    "        list_train_kappas.append(train_kappa)\n",
    "        list_valid_kappas.append(valid_kappa)\n",
    "    \n",
    "        y_test[:, fold] = model.predict(df_test)\n",
    "        clear_output(wait=True)\n",
    "            \n",
    "    print(f\"Mean Train QWK --> {np.mean(list_train_kappas):.4f}\")\n",
    "    print(f\"Mean Valid QWK --> {np.mean(list_valid_kappas):.4f}\")\n",
    "\n",
    "    # Grid sweep setup\n",
    "    threshold_ranges = [\n",
    "        np.linspace(0.25, 0.75, 101, endpoint=True),   # First threshold range\n",
    "        np.linspace(0.75, 1.25, 101, endpoint=True), # Second threshold range\n",
    "        [3],\n",
    "    ]\n",
    "\n",
    "    # Prepare the grid search\n",
    "    best_score = float('-inf')\n",
    "    best_thresholds = None\n",
    "\n",
    "    for thresholds in tqdm(product(*threshold_ranges)):\n",
    "        thresholds = sorted(thresholds)  # Ensure thresholds are in order\n",
    "        score = -evaluate_predictions(thresholds, y, oof_non_rounded)  # Flip back to positive\n",
    "        if score > best_score:\n",
    "            # print(\"Score: \", score, \"thresholds: \", thresholds)\n",
    "            best_score = score\n",
    "            best_thresholds = thresholds\n",
    "\n",
    "    threshold_ranges = [\n",
    "        [best_thresholds[0]],\n",
    "        [best_thresholds[1]],\n",
    "        np.linspace(best_thresholds[1], 3.5, 1001, endpoint=True)    # Third threshold range\n",
    "    ]\n",
    "\n",
    "    for thresholds in tqdm(product(*threshold_ranges)):\n",
    "        thresholds = sorted(thresholds)  # Ensure thresholds are in order\n",
    "        score = -evaluate_predictions(thresholds, y, oof_non_rounded)  # Flip back to positive\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_thresholds = thresholds\n",
    "    \n",
    "    oof_tuned = threshold_Rounder(oof_non_rounded, best_thresholds)\n",
    "    oof_kappa = quadratic_weighted_kappa(y, oof_tuned)\n",
    "\n",
    "    y_test = y_test.mean(axis=1)\n",
    "    y_test = threshold_Rounder(y_test, best_thresholds)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'id': sample['id'],\n",
    "            'sii': y_test\n",
    "        })\n",
    "\n",
    "    # write to the .txt\n",
    "    f.write(f\"Trial: {trial_number}\\n\")\n",
    "    f.write(f\"Params: {params}\\n\")\n",
    "    f.write(f\"Score: {best_score}\\n\")\n",
    "    f.write(f\"Thresholds: {best_thresholds}\\n\")\n",
    "    f.write(f\"Train Kappa: {np.mean(list_train_kappas):.4f}\\n\")\n",
    "    f.write(f\"Validation Kappa: {np.mean(list_valid_kappas):.4f}\\n\")\n",
    "    f.write(f\"Optimized OOF QWK: {oof_kappa:.3f}\\n\")\n",
    "    f.write(f\"Best Score: {best_score}\\n\\n\")\n",
    "    f.write(\"-\" * 100 + \"\\n\")\n",
    "    f.flush()\n",
    "\n",
    "    return -oof_kappa, submission, oof_tuned\n",
    "\n",
    "\n",
    "with open('LGBM_Optimization.txt', 'a') as f:\n",
    "    f.write('Submission 3 - Optimization started\\n')\n",
    "\n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, step=0.01),  # Replaced suggest_loguniform\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 300, step=50),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 7, step=1),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 16, 512, step=2),\n",
    "            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 16, 128),\n",
    "            'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0, step=0.01),  # Replaced suggest_uniform\n",
    "            'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0, step=0.01),  # Replaced suggest_uniform\n",
    "            'bagging_freq': trial.suggest_int('bagging_freq', 1, 10, step=1),\n",
    "            \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 10, step=1),\n",
    "            \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 10, step=1),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0, step=0.1),  # Replaced suggest_uniform\n",
    "            'colsample_bynode': trial.suggest_float('colsample_bynode', 0.5, 1.0, step=0.1),  # Replaced suggest_uniform\n",
    "            'verbose': -1, # Disable LightGBM verbose logging\n",
    "            'random_state': SEED\n",
    "        }\n",
    "\n",
    "        score, submission, oof_tuned = train(params, trial.number)\n",
    "        return score\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\", study_name=\"LGBM Optimization\")\n",
    "    study.optimize(objective, n_trials=num_trials)\n",
    "    best_params = study.best_params\n",
    "    best_score = study.best_value\n",
    "    print(f\"Best Score: {best_score}\")\n",
    "    print(f\"Best Params: {best_params}\")\n",
    "    \n",
    "    best_params['random_state'] = SEED\n",
    "    score, submission3, oof_tuned3 = train(best_params, study.best_trial.number)\n",
    "    print(\"Reproduced Score: \", score)\n",
    "\n",
    "submission3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ecf2a83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T07:09:53.185752Z",
     "iopub.status.busy": "2024-12-19T07:09:53.185351Z",
     "iopub.status.idle": "2024-12-19T07:09:53.213921Z",
     "shell.execute_reply": "2024-12-19T07:09:53.212911Z"
    },
    "papermill": {
     "duration": 0.136441,
     "end_time": "2024-12-19T07:09:53.215430",
     "exception": false,
     "start_time": "2024-12-19T07:09:53.078989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority voting completed and saved to 'Final_Submission.csv'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008ff9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fd460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00105258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00115b9f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016bb22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001f3379</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0038ba98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0068a485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0069fbed</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0083e397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0087dd65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00abe655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00ae59c9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00af6387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00bd4359</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00c0cd71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00d56d4b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00d9913d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00e6167c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00ebc35d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  sii\n",
       "0   00008ff9    0\n",
       "1   000fd460    0\n",
       "2   00105258    0\n",
       "3   00115b9f    0\n",
       "4   0016bb22    2\n",
       "5   001f3379    0\n",
       "6   0038ba98    1\n",
       "7   0068a485    0\n",
       "8   0069fbed    2\n",
       "9   0083e397    1\n",
       "10  0087dd65    1\n",
       "11  00abe655    1\n",
       "12  00ae59c9    1\n",
       "13  00af6387    1\n",
       "14  00bd4359    2\n",
       "15  00c0cd71    1\n",
       "16  00d56d4b    0\n",
       "17  00d9913d    0\n",
       "18  00e6167c    0\n",
       "19  00ebc35d    1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub1 = submission1\n",
    "sub2 = submission2\n",
    "sub3 = submission3\n",
    "\n",
    "sub1 = sub1.sort_values(by='id').reset_index(drop=True)\n",
    "sub2 = sub2.sort_values(by='id').reset_index(drop=True)\n",
    "sub3 = sub3.sort_values(by='id').reset_index(drop=True)\n",
    "\n",
    "combined = pd.DataFrame({\n",
    "    'id': sub1['id'],\n",
    "    'sii_1': sub1['sii'],\n",
    "    'sii_2': sub2['sii'],\n",
    "    'sii_3': sub3['sii'],\n",
    "})\n",
    "\n",
    "def majority_vote(row):\n",
    "    mode_values = row.mode()\n",
    "    return int(mode_values.median())\n",
    "    \n",
    "combined['sii'] = combined[['sii_1', 'sii_2', 'sii_3']].apply(majority_vote, axis=1)\n",
    "final_submission = combined[['id', 'sii']]\n",
    "final_submission.to_csv('submission.csv', index=False)\n",
    "print(\"Majority voting completed and saved to 'Final_Submission.csv'\")\n",
    "final_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63f13429",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T07:09:53.432872Z",
     "iopub.status.busy": "2024-12-19T07:09:53.432471Z",
     "iopub.status.idle": "2024-12-19T07:09:54.051240Z",
     "shell.execute_reply": "2024-12-19T07:09:54.049932Z"
    },
    "papermill": {
     "duration": 0.730395,
     "end_time": "2024-12-19T07:09:54.053008",
     "exception": false,
     "start_time": "2024-12-19T07:09:53.322613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa Score:  0.5037964888523481\n",
      "0    0.561404\n",
      "1    0.272295\n",
      "2    0.159357\n",
      "3    0.006944\n",
      "Name: proportion, dtype: float64\n",
      "sii\n",
      "0.0    0.582602\n",
      "1.0    0.266813\n",
      "2.0    0.138158\n",
      "3.0    0.012427\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_oof1 = pd.DataFrame(oof_tuned1, columns=['oof1'])\n",
    "df_oof2 = pd.DataFrame(oof_tuned2, columns=['oof2'])\n",
    "df_oof3 = pd.DataFrame(oof_tuned3, columns=['oof3'])\n",
    "\n",
    "df_oof_combined = pd.concat([df_oof1, df_oof2, df_oof3], axis=1).apply(majority_vote, axis=1)\n",
    "\n",
    "# compute the kappa score\n",
    "print('Kappa Score: ', quadratic_weighted_kappa(df_train['sii'], df_oof_combined))\n",
    "\n",
    "# print the percentage of each label in the oof_tuned and y\n",
    "print(df_oof_combined.value_counts(normalize=True))\n",
    "print(df_train['sii'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f23c088",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T07:09:54.268762Z",
     "iopub.status.busy": "2024-12-19T07:09:54.268358Z",
     "iopub.status.idle": "2024-12-19T07:09:54.282143Z",
     "shell.execute_reply": "2024-12-19T07:09:54.280904Z"
    },
    "papermill": {
     "duration": 0.124329,
     "end_time": "2024-12-19T07:09:54.283717",
     "exception": false,
     "start_time": "2024-12-19T07:09:54.159388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sii\n",
      "0.0    0.582602\n",
      "1.0    0.266813\n",
      "2.0    0.138158\n",
      "3.0    0.012427\n",
      "Name: proportion, dtype: float64 \n",
      "\n",
      "sii\n",
      "0    0.45\n",
      "1    0.30\n",
      "2    0.25\n",
      "Name: proportion, dtype: float64 \n",
      "\n",
      "sii\n",
      "1    0.55\n",
      "0    0.30\n",
      "2    0.15\n",
      "Name: proportion, dtype: float64 \n",
      "\n",
      "sii\n",
      "0    0.6\n",
      "1    0.4\n",
      "Name: proportion, dtype: float64 \n",
      "\n",
      "sii\n",
      "0    0.45\n",
      "1    0.40\n",
      "2    0.15\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_train['sii'].value_counts(normalize=True), '\\n')\n",
    "print(submission1['sii'].value_counts(normalize=True), '\\n')\n",
    "print(submission2['sii'].value_counts(normalize=True), '\\n')\n",
    "print(submission3['sii'].value_counts(normalize=True), '\\n')\n",
    "print(final_submission['sii'].value_counts(normalize=True))\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9643020,
     "sourceId": 81933,
     "sourceType": "competition"
    },
    {
     "datasetId": 921302,
     "sourceId": 7453542,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6240391,
     "sourceId": 10200497,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6311975,
     "sourceId": 10212404,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6035.767783,
   "end_time": "2024-12-19T07:09:56.887532",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-19T05:29:21.119749",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
