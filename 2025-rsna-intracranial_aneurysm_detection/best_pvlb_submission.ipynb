{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "169147ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T21:16:28.462709Z",
     "iopub.status.busy": "2025-10-02T21:16:28.461903Z",
     "iopub.status.idle": "2025-10-02T21:16:44.026318Z",
     "shell.execute_reply": "2025-10-02T21:16:44.025526Z"
    },
    "papermill": {
     "duration": 15.569198,
     "end_time": "2025-10-02T21:16:44.027698",
     "exception": false,
     "start_time": "2025-10-02T21:16:28.458500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/usr/local/lib/python3.11/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "/kaggle/input/rnsa-aneurysm-detection/src/coat.py:589: UserWarning: Overwriting coat_tiny in registry with src.coat.coat_tiny. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "/kaggle/input/rnsa-aneurysm-detection/src/coat.py:595: UserWarning: Overwriting coat_mini in registry with src.coat.coat_mini. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "/kaggle/input/rnsa-aneurysm-detection/src/coat.py:601: UserWarning: Overwriting coat_small in registry with src.coat.coat_small. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "/kaggle/input/rnsa-aneurysm-detection/src/coat.py:608: UserWarning: Overwriting coat_lite_tiny in registry with src.coat.coat_lite_tiny. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "/kaggle/input/rnsa-aneurysm-detection/src/coat.py:614: UserWarning: Overwriting coat_lite_mini in registry with src.coat.coat_lite_mini. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "/kaggle/input/rnsa-aneurysm-detection/src/coat.py:620: UserWarning: Overwriting coat_lite_small in registry with src.coat.coat_lite_small. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "/kaggle/input/rnsa-aneurysm-detection/src/coat.py:626: UserWarning: Overwriting coat_lite_medium in registry with src.coat.coat_lite_medium. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import pydicom\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "import kaggle_evaluation.rsna_inference_server\n",
    "\n",
    "# Add model source to path\n",
    "sys.path.append('/kaggle/input/rnsa-aneurysm-detection')\n",
    "sys.path.append('/kaggle/input/rnsa-aneurysm-detection/src')\n",
    "\n",
    "# Import model\n",
    "from model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933a47de",
   "metadata": {
    "papermill": {
     "duration": 0.001506,
     "end_time": "2025-10-02T21:16:44.031415",
     "exception": false,
     "start_time": "2025-10-02T21:16:44.029909",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The evaluation API requires that you set up a server which will respond to inference requests. We have already defined the server; you just need write the predict function. When we evaluate your submission on the hidden test set the client defined in `rsna_gateway` will run in a different container with direct access to the hidden test set and hand off the data series by series.\n",
    "\n",
    "Your code will always have access to the published copies of the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e8f7a86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T21:16:44.035797Z",
     "iopub.status.busy": "2025-10-02T21:16:44.035580Z",
     "iopub.status.idle": "2025-10-02T21:17:09.652063Z",
     "shell.execute_reply": "2025-10-02T21:17:09.651141Z"
    },
    "papermill": {
     "duration": 25.620404,
     "end_time": "2025-10-02T21:17:09.653404",
     "exception": false,
     "start_time": "2025-10-02T21:16:44.033000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "Model loaded successfully from /kaggle/input/rnsa-aneurysm-detection/ckpt/ckpt_exp6_ep44.pt\n",
      "Model loaded successfully from /kaggle/input/rnsa-aneurysm-detection/ckpt/ckpt_exp5_ep6.pt\n",
      "Model loaded successfully from /kaggle/input/rnsa-aneurysm-detection/ckpt/ckpt_exp8_fold1_ep16.pt\n",
      "Model loaded successfully from /kaggle/input/rnsa-aneurysm-detection/ckpt/ckpt_exp9_fold2_ep10.pt\n",
      "Model loaded successfully from /kaggle/input/rnsa-aneurysm-detection/ckpt/ckpt_exp9_fold3_ep25.pt\n",
      "Total models loaded: 5\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "ID_COL = 'SeriesInstanceUID'\n",
    "LABEL_COLS = [\n",
    "    'Left Infraclinoid Internal Carotid Artery',\n",
    "    'Right Infraclinoid Internal Carotid Artery',\n",
    "    'Left Supraclinoid Internal Carotid Artery',\n",
    "    'Right Supraclinoid Internal Carotid Artery',\n",
    "    'Left Middle Cerebral Artery',\n",
    "    'Right Middle Cerebral Artery',\n",
    "    'Anterior Communicating Artery',\n",
    "    'Left Anterior Cerebral Artery',\n",
    "    'Right Anterior Cerebral Artery',\n",
    "    'Left Posterior Communicating Artery',\n",
    "    'Right Posterior Communicating Artery',\n",
    "    'Basilar Tip',\n",
    "    'Other Posterior Circulation',\n",
    "    'Aneurysm Present',\n",
    "]\n",
    "\n",
    "# ImageNet normalization\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# List of checkpoint paths\n",
    "CHECKPOINT_PATHS = [\n",
    "    \"/kaggle/input/rnsa-aneurysm-detection/ckpt/ckpt_exp6_ep44.pt\",\n",
    "    \"/kaggle/input/rnsa-aneurysm-detection/ckpt/ckpt_exp5_ep6.pt\",\n",
    "    \"/kaggle/input/rnsa-aneurysm-detection/ckpt/ckpt_exp8_fold1_ep16.pt\",\n",
    "    \"/kaggle/input/rnsa-aneurysm-detection/ckpt/ckpt_exp9_fold2_ep10.pt\",\n",
    "    \"/kaggle/input/rnsa-aneurysm-detection/ckpt/ckpt_exp9_fold3_ep25.pt\",\n",
    "]\n",
    "\n",
    "# Initialize models globally - loads once when module is imported\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"Loading models...\")\n",
    "models = []\n",
    "for checkpoint_path in CHECKPOINT_PATHS:\n",
    "    model = Model(\n",
    "        pre=None,\n",
    "        num_classes=14,\n",
    "        ps=0.1,\n",
    "        mask_head=False\n",
    "    ).to(device)\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    models.append(model)\n",
    "    print(f\"Model loaded successfully from {checkpoint_path}\")\n",
    "\n",
    "print(f\"Total models loaded: {len(models)}\")\n",
    "\n",
    "def get_slice_position(ds):\n",
    "    \"\"\"Get slice position for sorting\"\"\"\n",
    "    if hasattr(ds, 'ImagePositionPatient') and ds.ImagePositionPatient:\n",
    "        return float(ds.ImagePositionPatient[2])\n",
    "    if hasattr(ds, 'SliceLocation'):\n",
    "        return float(ds.SliceLocation)\n",
    "    if hasattr(ds, 'InstanceNumber'):\n",
    "        return float(ds.InstanceNumber)\n",
    "    return 0.0\n",
    "\n",
    "def should_rescale_ct(ds, pixel_array):\n",
    "    \"\"\"Determine if CT should be rescaled\"\"\"\n",
    "    if ds.get('Modality', '') != 'CT':\n",
    "        return False\n",
    "    if not (hasattr(ds, 'RescaleSlope') and hasattr(ds, 'RescaleIntercept')):\n",
    "        return False\n",
    "    min_pixel = pixel_array.min()\n",
    "    if min_pixel >= -100 or min_pixel == -2000:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def resize_slice_to_384(slice_array):\n",
    "    \"\"\"Resize slice to 384x384 using cubic interpolation\"\"\"\n",
    "    if slice_array.shape == (384, 384):\n",
    "        return slice_array\n",
    "    \n",
    "    try:\n",
    "        resized = cv2.resize(slice_array.astype(np.float32), (384, 384), \n",
    "                           interpolation=cv2.INTER_CUBIC)\n",
    "        return resized\n",
    "    except:\n",
    "        from scipy.ndimage import zoom\n",
    "        zoom_factors = (384 / slice_array.shape[0], 384 / slice_array.shape[1])\n",
    "        return zoom(slice_array.astype(np.float32), zoom_factors, order=3)\n",
    "\n",
    "def normalize_slab(slab):\n",
    "    \"\"\"Apply ImageNet normalization to slab\"\"\"\n",
    "    for c in range(3):\n",
    "        slab[c] = (slab[c] - IMAGENET_MEAN[c]) / IMAGENET_STD[c]\n",
    "    return slab\n",
    "\n",
    "def process_dicom_series(series_path):\n",
    "    \"\"\"Process DICOM series into 384x384 volume\"\"\"\n",
    "    dcm_files = []\n",
    "    for root, _, files in os.walk(series_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.dcm'):\n",
    "                dcm_files.append(os.path.join(root, file))\n",
    "    \n",
    "    if len(dcm_files) == 0:\n",
    "        raise ValueError(\"No DICOM files found\")\n",
    "    \n",
    "    slice_data = []\n",
    "    for dcm_file in dcm_files:\n",
    "        try:\n",
    "            ds = pydicom.dcmread(dcm_file, force=True)\n",
    "            pixel_array = ds.pixel_array\n",
    "            \n",
    "            if len(pixel_array.shape) == 3:\n",
    "                for slice_idx in range(pixel_array.shape[0]):\n",
    "                    slice_position = get_slice_position(ds) + slice_idx\n",
    "                    slice_data.append({\n",
    "                        'dataset': ds,\n",
    "                        'pixel_array': pixel_array[slice_idx],\n",
    "                        'position': slice_position\n",
    "                    })\n",
    "            else:\n",
    "                slice_data.append({\n",
    "                    'dataset': ds,\n",
    "                    'pixel_array': pixel_array,\n",
    "                    'position': get_slice_position(ds)\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {dcm_file}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if len(slice_data) == 0:\n",
    "        raise ValueError(\"No valid slices found\")\n",
    "    \n",
    "    slice_data.sort(key=lambda x: x['position'])\n",
    "    \n",
    "    processed_slices = []\n",
    "    first_ds = slice_data[0]['dataset']\n",
    "    modality = first_ds.get('Modality', 'Unknown')\n",
    "    \n",
    "    for slice_info in slice_data:\n",
    "        ds = slice_info['dataset']\n",
    "        pixel_array = slice_info['pixel_array']\n",
    "        \n",
    "        if modality == 'CT':\n",
    "            if should_rescale_ct(ds, pixel_array):\n",
    "                slope = float(ds.RescaleSlope)\n",
    "                intercept = float(ds.RescaleIntercept)\n",
    "                hu_array = pixel_array * slope + intercept\n",
    "            else:\n",
    "                hu_array = pixel_array.astype(np.float32)\n",
    "        else:\n",
    "            slope = float(getattr(ds, 'RescaleSlope', 1.0))\n",
    "            intercept = float(getattr(ds, 'RescaleIntercept', 0.0))\n",
    "            hu_array = pixel_array * slope + intercept\n",
    "        \n",
    "        resized_slice = resize_slice_to_384(hu_array)\n",
    "        processed_slices.append(resized_slice)\n",
    "    \n",
    "    volume = np.stack(processed_slices, axis=0)\n",
    "    \n",
    "    global_min = volume.min()\n",
    "    global_max = volume.max()\n",
    "    \n",
    "    if global_max - global_min == 0:\n",
    "        volume_uint8 = np.zeros_like(volume, dtype=np.uint8)\n",
    "    else:\n",
    "        normalized = (volume - global_min) / (global_max - global_min)\n",
    "        volume_uint8 = (normalized * 255).astype(np.uint8)\n",
    "    \n",
    "    return volume_uint8\n",
    "\n",
    "def create_slabs(volume, slab_size=3):\n",
    "    \"\"\"Create slabs of 3 slices from volume with minimal overlap\"\"\"\n",
    "    num_slices = volume.shape[0]\n",
    "    slabs = []\n",
    "    \n",
    "    if num_slices <= slab_size:\n",
    "        if num_slices == 1:\n",
    "            slab = np.stack([volume[0], volume[0], volume[0]], axis=0)\n",
    "        elif num_slices == 2:\n",
    "            slab = np.stack([volume[0], volume[1], volume[1]], axis=0)\n",
    "        else:\n",
    "            slab = volume\n",
    "        slabs.append(slab)\n",
    "    else:\n",
    "        num_complete_slabs = num_slices // slab_size\n",
    "        for i in range(num_complete_slabs):\n",
    "            start_idx = i * slab_size\n",
    "            slab = volume[start_idx:start_idx + slab_size]\n",
    "            slabs.append(slab)\n",
    "        \n",
    "        remainder = num_slices % slab_size\n",
    "        if remainder != 0:\n",
    "            last_slab = volume[-slab_size:]\n",
    "            slabs.append(last_slab)\n",
    "    \n",
    "    return slabs\n",
    "\n",
    "def predict(series_path: str) -> pl.DataFrame:\n",
    "    \"\"\"Make predictions for a DICOM series using ensemble of models with batch processing\"\"\"\n",
    "    try:\n",
    "        # Use global models directly (already loaded at module level)\n",
    "        series_id = os.path.basename(series_path)\n",
    "        \n",
    "        volume_uint8 = process_dicom_series(series_path)\n",
    "        print(f\"Processed volume shape: {volume_uint8.shape}\")\n",
    "        \n",
    "        slabs = create_slabs(volume_uint8, slab_size=3)\n",
    "        print(f\"Created {len(slabs)} slabs\")\n",
    "        \n",
    "        # Store predictions from all models\n",
    "        model_predictions = []\n",
    "        \n",
    "        # Run inference with each model\n",
    "        for model_idx, model in enumerate(models):\n",
    "            all_predictions = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # Process slabs in batches of 32\n",
    "                batch_size = 32\n",
    "                for i in range(0, len(slabs), batch_size):\n",
    "                    batch_slabs = slabs[i:i + batch_size]\n",
    "                    \n",
    "                    # Prepare batch tensor\n",
    "                    batch_tensors = []\n",
    "                    for slab in batch_slabs:\n",
    "                        slab_float = slab.astype(np.float32) / 255.0\n",
    "                        slab_normalized = normalize_slab(slab_float.copy())\n",
    "                        slab_tensor = torch.from_numpy(slab_normalized).float()\n",
    "                        batch_tensors.append(slab_tensor)\n",
    "                    \n",
    "                    # Stack into batch\n",
    "                    batch_tensor = torch.stack(batch_tensors, dim=0).to(device)\n",
    "                    \n",
    "                    # Get predictions for batch\n",
    "                    cls_output, _ = model(batch_tensor)\n",
    "                    predictions = torch.sigmoid(cls_output)\n",
    "                    all_predictions.append(predictions.cpu())\n",
    "            \n",
    "            if len(all_predictions) > 0:\n",
    "                all_predictions = torch.cat(all_predictions, dim=0)\n",
    "                final_predictions = torch.max(all_predictions, dim=0)[0].numpy()\n",
    "            else:\n",
    "                final_predictions = np.zeros(14)\n",
    "            \n",
    "            model_predictions.append(final_predictions)\n",
    "            print(f\"Model {model_idx + 1} predictions for {series_id}: {final_predictions}\")\n",
    "        \n",
    "        # Calculate mean prediction across all models\n",
    "        final_predictions = np.mean(model_predictions, axis=0)\n",
    "        print(f\"Mean ensemble predictions for {series_id}: {final_predictions}\")\n",
    "        \n",
    "        result_data = [[series_id] + final_predictions.tolist()]\n",
    "        predictions_df = pl.DataFrame(\n",
    "            data=result_data,\n",
    "            schema=[ID_COL, *LABEL_COLS],\n",
    "            orient='row',\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {series_path}: {e}\")\n",
    "        predictions_df = pl.DataFrame(\n",
    "            data=[[series_id] + [0.5] * len(LABEL_COLS)],\n",
    "            schema=[ID_COL, *LABEL_COLS],\n",
    "            orient='row',\n",
    "        )\n",
    "    \n",
    "    shutil.rmtree('/kaggle/shared', ignore_errors=True)\n",
    "    \n",
    "    return predictions_df.drop(ID_COL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304d1204",
   "metadata": {
    "papermill": {
     "duration": 0.002665,
     "end_time": "2025-10-02T21:17:09.659552",
     "exception": false,
     "start_time": "2025-10-02T21:17:09.656887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When your notebook is run on the hidden test set, `inference_server.serve` must be called within 15 minutes of the notebook starting or the gateway will throw an error. If you need more than 15 minutes to load your model you can do so during the very first `predict` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deb64e0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-02T21:17:09.667005Z",
     "iopub.status.busy": "2025-10-02T21:17:09.666607Z",
     "iopub.status.idle": "2025-10-02T21:18:01.899384Z",
     "shell.execute_reply": "2025-10-02T21:18:01.898623Z"
    },
    "papermill": {
     "duration": 52.238087,
     "end_time": "2025-10-02T21:18:01.900718",
     "exception": false,
     "start_time": "2025-10-02T21:17:09.662631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed volume shape: (176, 384, 384)\n",
      "Created 59 slabs\n",
      "Model 1 predictions for 1.2.826.0.1.3680043.8.498.10028406715369553772267826812576760572: [1.08479544e-04 7.98903685e-03 3.95630836e-04 1.94816440e-02\n",
      " 9.43214595e-01 2.86105368e-03 1.07355630e-02 3.43987660e-04\n",
      " 9.03945824e-04 2.18437955e-04 1.03904679e-03 4.22077865e-05\n",
      " 6.82897747e-01 9.63146687e-01]\n",
      "Model 2 predictions for 1.2.826.0.1.3680043.8.498.10028406715369553772267826812576760572: [0.00876737 0.01225688 0.27784508 0.07556773 0.2073177  0.24037255\n",
      " 0.04116516 0.0195063  0.05652323 0.23192322 0.07079834 0.06500311\n",
      " 0.06092188 0.7181832 ]\n",
      "Model 3 predictions for 1.2.826.0.1.3680043.8.498.10028406715369553772267826812576760572: [6.8103801e-04 1.0048762e-03 4.1038734e-03 1.9241272e-02 6.5669268e-03\n",
      " 8.9743900e-01 3.1658872e-03 1.8624212e-03 1.9396362e-03 1.6632354e-02\n",
      " 3.4094849e-03 7.4304151e-03 2.6800539e-03 7.5367957e-01]\n",
      "Model 4 predictions for 1.2.826.0.1.3680043.8.498.10028406715369553772267826812576760572: [2.1193529e-02 2.3929852e-03 1.4327091e-01 1.0411924e-01 1.1568663e-02\n",
      " 2.0640649e-02 7.7828996e-02 3.2732457e-02 3.2965836e-01 1.2369394e-02\n",
      " 2.4925965e-01 3.6128474e-04 2.5238925e-01 9.2155790e-01]\n",
      "Model 5 predictions for 1.2.826.0.1.3680043.8.498.10028406715369553772267826812576760572: [1.9492315e-04 1.0712153e-03 2.1200817e-02 5.7279109e-04 3.2412815e-03\n",
      " 9.9050319e-01 2.4113057e-02 4.4406703e-04 1.9335202e-03 2.7106682e-05\n",
      " 1.6972339e-05 2.8918330e-05 8.5288350e-04 9.6455139e-01]\n",
      "Mean ensemble predictions for 1.2.826.0.1.3680043.8.498.10028406715369553772267826812576760572: [0.00618907 0.004943   0.08936326 0.04379654 0.23438182 0.43036327\n",
      " 0.03140173 0.01097785 0.07819174 0.0522341  0.0649047  0.01457319\n",
      " 0.19994837 0.8642238 ]\n",
      "Processed volume shape: (45, 384, 384)\n",
      "Created 15 slabs\n",
      "Model 1 predictions for 1.2.826.0.1.3680043.8.498.10076849691931487952247065581008547232: [1.4134510e-03 2.7895364e-04 2.8145360e-04 1.9254688e-04 3.9022241e-02\n",
      " 1.1107710e-04 1.5399040e-04 9.1721077e-04 5.6587603e-05 1.9158237e-05\n",
      " 1.0955203e-05 3.4249388e-02 1.4193320e-02 3.2522815e-01]\n",
      "Model 2 predictions for 1.2.826.0.1.3680043.8.498.10076849691931487952247065581008547232: [4.4377983e-02 1.7937202e-03 3.7521415e-03 2.4708807e-03 1.3840491e-02\n",
      " 4.7852613e-02 2.7181484e-02 6.4709173e-03 5.7943969e-04 3.9864363e-04\n",
      " 4.1489711e-04 2.3666948e-01 1.4028898e-02 5.1598293e-01]\n",
      "Model 3 predictions for 1.2.826.0.1.3680043.8.498.10076849691931487952247065581008547232: [4.2480850e-03 1.1242605e-02 3.4874736e-04 3.3263013e-02 1.3469530e-02\n",
      " 1.8593267e-03 3.8364905e-01 5.3552655e-04 4.8190803e-04 1.5668381e-03\n",
      " 3.0440136e-04 1.1125024e-03 8.2685810e-04 1.7361373e-01]\n",
      "Model 4 predictions for 1.2.826.0.1.3680043.8.498.10076849691931487952247065581008547232: [0.00133913 0.01796434 0.00413451 0.00074124 0.00360379 0.00530807\n",
      " 0.00158277 0.0014519  0.00165778 0.00233778 0.09937932 0.06783503\n",
      " 0.31926534 0.53030634]\n",
      "Model 5 predictions for 1.2.826.0.1.3680043.8.498.10076849691931487952247065581008547232: [1.3988848e-04 9.4147902e-03 5.8252370e-04 2.9919425e-03 5.8221561e-03\n",
      " 1.0253218e-03 7.2406304e-01 2.7988155e-03 1.2622250e-02 1.8051391e-05\n",
      " 3.2335469e-05 3.9473074e-03 6.0135714e-04 3.9673963e-01]\n",
      "Mean ensemble predictions for 1.2.826.0.1.3680043.8.498.10076849691931487952247065581008547232: [0.01030371 0.00813888 0.00181987 0.00793192 0.01515164 0.01123128\n",
      " 0.22732607 0.00243487 0.00307959 0.00086809 0.02002838 0.06876274\n",
      " 0.06978315 0.38837415]\n",
      "Processed volume shape: (863, 384, 384)\n",
      "Created 288 slabs\n",
      "Model 1 predictions for 1.2.826.0.1.3680043.8.498.10057359944432090722321480667591403108: [9.4471319e-04 8.5932672e-01 5.0749516e-01 2.9740253e-01 5.1654773e-05\n",
      " 2.9869184e-03 2.7174234e-01 2.3157356e-04 4.9818391e-03 2.4583031e-04\n",
      " 5.5136628e-05 1.4202757e-04 4.4151074e-03 5.3594178e-01]\n",
      "Model 2 predictions for 1.2.826.0.1.3680043.8.498.10057359944432090722321480667591403108: [0.53822094 0.07588569 0.17216715 0.10068915 0.10411259 0.6348986\n",
      " 0.0183173  0.00907889 0.07634301 0.02146734 0.00671452 0.64276177\n",
      " 0.09183007 0.7467561 ]\n",
      "Model 3 predictions for 1.2.826.0.1.3680043.8.498.10057359944432090722321480667591403108: [0.00500923 0.00387216 0.00615255 0.13731632 0.34138605 0.2041517\n",
      " 0.01889727 0.00059627 0.00181484 0.04415914 0.5222204  0.1925403\n",
      " 0.00457315 0.43954974]\n",
      "Model 4 predictions for 1.2.826.0.1.3680043.8.498.10057359944432090722321480667591403108: [0.02148847 0.39966428 0.18044089 0.2526396  0.02206907 0.10641457\n",
      " 0.01519708 0.02397307 0.03846795 0.00849372 0.3806693  0.00112151\n",
      " 0.07357082 0.51030195]\n",
      "Model 5 predictions for 1.2.826.0.1.3680043.8.498.10057359944432090722321480667591403108: [1.0992755e-03 2.3127196e-03 1.7351462e-02 1.1757992e-01 1.3684587e-01\n",
      " 8.7183289e-02 3.3319259e-01 3.2553757e-03 2.0761609e-03 2.1611287e-03\n",
      " 8.9675683e-04 6.7536352e-04 2.8581875e-03 9.0790486e-01]\n",
      "Mean ensemble predictions for 1.2.826.0.1.3680043.8.498.10057359944432090722321480667591403108: [0.11335254 0.26821232 0.17672145 0.1811255  0.12089305 0.207127\n",
      " 0.13146931 0.00742704 0.02473676 0.01530543 0.18211122 0.1674482\n",
      " 0.03544947 0.6280909 ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 15)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>SeriesInstanceUID</th><th>Left Infraclinoid Internal Carotid Artery</th><th>Right Infraclinoid Internal Carotid Artery</th><th>Left Supraclinoid Internal Carotid Artery</th><th>Right Supraclinoid Internal Carotid Artery</th><th>Left Middle Cerebral Artery</th><th>Right Middle Cerebral Artery</th><th>Anterior Communicating Artery</th><th>Left Anterior Cerebral Artery</th><th>Right Anterior Cerebral Artery</th><th>Left Posterior Communicating Artery</th><th>Right Posterior Communicating Artery</th><th>Basilar Tip</th><th>Other Posterior Circulation</th><th>Aneurysm Present</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;1.2.826.0.1.3680043.8.498.1002…</td><td>0.006189</td><td>0.004943</td><td>0.089363</td><td>0.043797</td><td>0.234382</td><td>0.430363</td><td>0.031402</td><td>0.010978</td><td>0.078192</td><td>0.052234</td><td>0.064905</td><td>0.014573</td><td>0.199948</td><td>0.864224</td></tr><tr><td>&quot;1.2.826.0.1.3680043.8.498.1007…</td><td>0.010304</td><td>0.008139</td><td>0.00182</td><td>0.007932</td><td>0.015152</td><td>0.011231</td><td>0.227326</td><td>0.002435</td><td>0.00308</td><td>0.000868</td><td>0.020028</td><td>0.068763</td><td>0.069783</td><td>0.388374</td></tr><tr><td>&quot;1.2.826.0.1.3680043.8.498.1005…</td><td>0.113353</td><td>0.268212</td><td>0.176721</td><td>0.181126</td><td>0.120893</td><td>0.207127</td><td>0.131469</td><td>0.007427</td><td>0.024737</td><td>0.015305</td><td>0.182111</td><td>0.167448</td><td>0.035449</td><td>0.628091</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 15)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ SeriesIns ┆ Left Infr ┆ Right Inf ┆ Left Supr ┆ … ┆ Right     ┆ Basilar   ┆ Other     ┆ Aneurysm │\n",
       "│ tanceUID  ┆ aclinoid  ┆ raclinoid ┆ aclinoid  ┆   ┆ Posterior ┆ Tip       ┆ Posterior ┆ Present  │\n",
       "│ ---       ┆ Internal  ┆ Internal  ┆ Internal  ┆   ┆ Communica ┆ ---       ┆ Circulati ┆ ---      │\n",
       "│ str       ┆ Car…      ┆ Ca…       ┆ Car…      ┆   ┆ ting …    ┆ f64       ┆ on        ┆ f64      │\n",
       "│           ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆           ┆ ---       ┆          │\n",
       "│           ┆ f64       ┆ f64       ┆ f64       ┆   ┆ f64       ┆           ┆ f64       ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 1.2.826.0 ┆ 0.006189  ┆ 0.004943  ┆ 0.089363  ┆ … ┆ 0.064905  ┆ 0.014573  ┆ 0.199948  ┆ 0.864224 │\n",
       "│ .1.368004 ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3.8.498.1 ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 002…      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 1.2.826.0 ┆ 0.010304  ┆ 0.008139  ┆ 0.00182   ┆ … ┆ 0.020028  ┆ 0.068763  ┆ 0.069783  ┆ 0.388374 │\n",
       "│ .1.368004 ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3.8.498.1 ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 007…      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 1.2.826.0 ┆ 0.113353  ┆ 0.268212  ┆ 0.176721  ┆ … ┆ 0.182111  ┆ 0.167448  ┆ 0.035449  ┆ 0.628091 │\n",
       "│ .1.368004 ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3.8.498.1 ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 005…      ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize inference server\n",
    "inference_server = kaggle_evaluation.rsna_inference_server.RSNAInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway()\n",
    "    # Display results for local testing\n",
    "    if os.path.exists('/kaggle/working/submission.parquet'):\n",
    "        display(pl.read_parquet('/kaggle/working/submission.parquet'))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 13851420,
     "sourceId": 99552,
     "sourceType": "competition"
    },
    {
     "datasetId": 8366804,
     "sourceId": 13245474,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 100.3196,
   "end_time": "2025-10-02T21:18:04.568041",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-02T21:16:24.248441",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
