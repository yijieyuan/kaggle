{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2802e92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4326 series in volume directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing series: 100%|██████████| 4326/4326 [46:35<00:00,  1.55it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PROCESSING COMPLETE\n",
      "============================================================\n",
      "Total series found: 4326\n",
      "Successfully processed: 1842\n",
      "Skipped (no targets): 2484\n",
      "Failed: 0\n",
      "============================================================\n",
      "\n",
      "Output directories:\n",
      "  Attention maps: E:\\kaggle-rsna-data_processing3\\att_map_z\n",
      "  Slice labels: .\\slice_level_label_z\n",
      "\n",
      "Generated files:\n",
      "  Attention maps: 1842\n",
      "  Slice labels: 1842\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def generate_attention_map(volume_shape, target_pct, std=5):\n",
    "    \"\"\"Generate attention heatmap for a volume with multiple targets\n",
    "    \n",
    "    Args:\n",
    "        volume_shape: (depth, height, width) - shape of the volume\n",
    "        target_pct: (N, 3) array of [x_pct, y_pct, z_pct]\n",
    "        std: standard deviation for Gaussian blur in pixels\n",
    "    \n",
    "    Returns:\n",
    "        attention_map: (depth, height, width) array with values in [0, 1]\n",
    "    \"\"\"\n",
    "    depth, height, width = volume_shape\n",
    "    \n",
    "    # Initialize final attention map\n",
    "    att_map_aggregated = np.zeros(volume_shape, dtype=np.float32)\n",
    "    \n",
    "    # Process each target\n",
    "    for target in target_pct:\n",
    "        x_pct, y_pct, z_pct = target\n",
    "        \n",
    "        # Convert percentages to indices\n",
    "        z_idx = int(z_pct * depth)\n",
    "        row_idx = int(y_pct * height)\n",
    "        col_idx = int(x_pct * width)\n",
    "        \n",
    "        # Clamp to valid range\n",
    "        z_idx = max(0, min(z_idx, depth - 1))\n",
    "        row_idx = max(0, min(row_idx, height - 1))\n",
    "        col_idx = max(0, min(col_idx, width - 1))\n",
    "        \n",
    "        # Create individual attention map for this target\n",
    "        att_map_single = np.zeros(volume_shape, dtype=np.float32)\n",
    "        att_map_single[z_idx, row_idx, col_idx] = 1.0\n",
    "        \n",
    "        # Apply 3D Gaussian blur\n",
    "        from scipy.ndimage import gaussian_filter\n",
    "        att_map_blurred = gaussian_filter(att_map_single, sigma=std, mode='constant')\n",
    "        \n",
    "        # Normalize to [0, 1]\n",
    "        max_val = att_map_blurred.max()\n",
    "        if max_val > 0:\n",
    "            att_map_blurred = att_map_blurred / max_val\n",
    "        \n",
    "        # Maximum aggregation\n",
    "        att_map_aggregated = np.maximum(att_map_aggregated, att_map_blurred)\n",
    "    \n",
    "    return att_map_aggregated\n",
    "\n",
    "\n",
    "def generate_slice_labels(target_pct, target_cls, depth=256, num_classes=14):\n",
    "    \"\"\"Generate slice-level labels for a volume (binary labels at exact indices)\n",
    "    \n",
    "    Args:\n",
    "        target_pct: (N, 3) array of [x_pct, y_pct, z_pct]\n",
    "        target_cls: (N,) array of class indices for each target\n",
    "        depth: depth dimension (default 256)\n",
    "        num_classes: number of condition classes (default 14)\n",
    "    \n",
    "    Returns:\n",
    "        slice_labels: (num_classes+1, depth) array \n",
    "                      First 14 rows for each class, last row is maximum of all\n",
    "                      Values are binary: 1 at exact target indices, 0 elsewhere\n",
    "    \"\"\"\n",
    "    # Initialize slice labels: (14, 256)\n",
    "    slice_labels = np.zeros((num_classes, depth), dtype=np.float32)\n",
    "    \n",
    "    # Process each target\n",
    "    for target, cls_idx in zip(target_pct, target_cls):\n",
    "        x_pct, y_pct, z_pct = target\n",
    "        \n",
    "        # Get z index\n",
    "        z_idx = int(z_pct * depth)\n",
    "        z_idx = max(0, min(z_idx, depth - 1))\n",
    "        \n",
    "        # Set label to 1 at the exact index for this class\n",
    "        slice_labels[cls_idx, z_idx] = 1.0\n",
    "    \n",
    "    # Add last row as maximum of all classes\n",
    "    slice_labels_with_max = np.zeros((num_classes + 1, depth), dtype=np.float32)\n",
    "    slice_labels_with_max[:num_classes, :] = slice_labels\n",
    "    slice_labels_with_max[-1, :] = np.maximum.reduce(slice_labels, axis=0)\n",
    "    \n",
    "    return slice_labels_with_max\n",
    "\n",
    "\n",
    "def process_series_attention_and_labels(series_uid, volume_dir, target_pct_dir, \n",
    "                                       target_cls_dir, att_map_dir, slice_label_dir):\n",
    "    \"\"\"Process a single series to generate attention map and slice labels\n",
    "    \n",
    "    Args:\n",
    "        series_uid: series identifier\n",
    "        volume_dir: directory containing volumes\n",
    "        target_pct_dir: directory containing target percentages\n",
    "        target_cls_dir: directory containing target class labels\n",
    "        att_map_dir: output directory for attention maps\n",
    "        slice_label_dir: output directory for slice labels\n",
    "    \n",
    "    Returns:\n",
    "        success: True if processed successfully\n",
    "    \"\"\"\n",
    "    # Check if target file exists\n",
    "    target_pct_file = Path(target_pct_dir) / f\"{series_uid}.npy\"\n",
    "    if not target_pct_file.exists():\n",
    "        return False  # No targets, skip\n",
    "    \n",
    "    # Load volume to get shape\n",
    "    volume_file = Path(volume_dir) / f\"{series_uid}.npy\"\n",
    "    if not volume_file.exists():\n",
    "        print(f\"Warning: Volume not found for {series_uid}\")\n",
    "        return False\n",
    "    \n",
    "    volume = np.load(volume_file)\n",
    "    volume_shape = volume.shape\n",
    "    \n",
    "    # Load target percentages\n",
    "    target_pct = np.load(target_pct_file)\n",
    "    \n",
    "    # Load target classes\n",
    "    target_cls_file = Path(target_cls_dir) / f\"{series_uid}.npy\"\n",
    "    if not target_cls_file.exists():\n",
    "        print(f\"Warning: Target classes not found for {series_uid}\")\n",
    "        return False\n",
    "    \n",
    "    target_cls = np.load(target_cls_file)\n",
    "    \n",
    "    # Validate dimensions\n",
    "    if len(target_pct) != len(target_cls):\n",
    "        print(f\"Warning: Mismatch in target counts for {series_uid}: {len(target_pct)} vs {len(target_cls)}\")\n",
    "        return False\n",
    "    \n",
    "    # Generate attention map\n",
    "    att_map = generate_attention_map(volume_shape, target_pct, std=5)\n",
    "    \n",
    "    # Save attention map\n",
    "    np.save(Path(att_map_dir) / f\"{series_uid}.npy\", att_map.astype(np.float32))\n",
    "    \n",
    "    # Generate slice labels (assuming depth=256) - now binary at exact indices\n",
    "    slice_labels = generate_slice_labels(target_pct, target_cls, depth=256, num_classes=14)\n",
    "    \n",
    "    # Save slice labels\n",
    "    np.save(Path(slice_label_dir) / f\"{series_uid}.npy\", slice_labels)\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Paths\n",
    "    volume_dir =  r\"E:\\kaggle-rsna-data_processing3\\volume_uint8_256_z\"\n",
    "    target_pct_dir = r\"E:\\kaggle-rsna-data_processing3\\label_percentage_z\"\n",
    "    target_cls_dir = r\"E:\\kaggle-rsna-crop2\\target_cls\"\n",
    "    \n",
    "    att_map_dir = r\"E:\\kaggle-rsna-data_processing3\\att_map_z\"\n",
    "    slice_label_dir = r\".\\slice_level_label_z\"\n",
    "    \n",
    "    # Create output directories\n",
    "    Path(att_map_dir).mkdir(parents=True, exist_ok=True)\n",
    "    Path(slice_label_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Get all series from volume directory\n",
    "    volume_files = list(Path(volume_dir).glob(\"*.npy\"))\n",
    "    series_uids = [f.stem for f in volume_files]\n",
    "    \n",
    "    print(f\"Found {len(series_uids)} series in volume directory\")\n",
    "    \n",
    "    # Statistics\n",
    "    successful = 0\n",
    "    skipped_no_targets = 0\n",
    "    failed = 0\n",
    "    \n",
    "    # Process all series\n",
    "    for series_uid in tqdm(series_uids, desc=\"Processing series\"):\n",
    "        try:\n",
    "            success = process_series_attention_and_labels(\n",
    "                series_uid,\n",
    "                volume_dir,\n",
    "                target_pct_dir,\n",
    "                target_cls_dir,\n",
    "                att_map_dir,\n",
    "                slice_label_dir\n",
    "            )\n",
    "            \n",
    "            if success:\n",
    "                successful += 1\n",
    "            else:\n",
    "                skipped_no_targets += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"\\nERROR processing {series_uid}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            failed += 1\n",
    "            continue\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PROCESSING COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total series found: {len(series_uids)}\")\n",
    "    print(f\"Successfully processed: {successful}\")\n",
    "    print(f\"Skipped (no targets): {skipped_no_targets}\")\n",
    "    print(f\"Failed: {failed}\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nOutput directories:\")\n",
    "    print(f\"  Attention maps: {att_map_dir}\")\n",
    "    print(f\"  Slice labels: {slice_label_dir}\")\n",
    "    \n",
    "    # Verify outputs\n",
    "    att_map_count = len(list(Path(att_map_dir).glob(\"*.npy\")))\n",
    "    slice_label_count = len(list(Path(slice_label_dir).glob(\"*.npy\")))\n",
    "    print(f\"\\nGenerated files:\")\n",
    "    print(f\"  Attention maps: {att_map_count}\")\n",
    "    print(f\"  Slice labels: {slice_label_count}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4906bf08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yyuan57",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
